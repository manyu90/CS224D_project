{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.models.rnn import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/abhimanyu/GitHub/Project_cs224D/mnist(Projectcode&poster)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding=np.loadtxt('../../Project_cs224D/w2v_data1Bmedline/embedding_matrix')\n",
    "with open('../../Project_cs224D/w2v_data1Bmedline/dictionary.pickle','rb') as handle:\n",
    "    dictionary=pickle.load(handle)\n",
    "with open('../../Project_cs224D/w2v_data1Bmedline/reverse_dictionary.pickle','rb') as handle:\n",
    "    reverse_dictionary=pickle.load(handle)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245214\n"
     ]
    }
   ],
   "source": [
    "print len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Relations/relations_label_dict_new.pickle','rb') as handle:\n",
    "    relations=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences, labels = zip(*[(key, value) for (key, value) in relations.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping={-1:(0,1),1:(1,0)}\n",
    "labels=[mapping[label] for label in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(10)\n",
    "print a[:4]\n",
    "print a[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DEFINING THE TRAINING AND TESTING DATA HERE\n",
    "\n",
    "\n",
    "train_sentences=sentences[:1600]\n",
    "test_sentences=sentences[1600:1900]\n",
    "dev_sentences=sentences[1900:]\n",
    "train_labels=labels[:1600]\n",
    "test_labels=labels[1600:1900]\n",
    "dev_labels=labels[1900:]\n",
    "#print len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81438\n",
      "2157\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "lengths_sents=[len(sent) for sent in sentences]\n",
    "print np.sum(lengths_sents)\n",
    "print len(lengths_sents)\n",
    "print np.sum(lengths_sents)/len(lengths_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###ADDED THE PAD symbol to the embedding at the end. IT is all zeros\n",
    "###The dictionary is updated as well\n",
    "\n",
    "embedding=np.vstack([embedding,np.zeros(128)])\n",
    "dictionary['PAD']=len(embedding)-1\n",
    "reverse_dictionary[len(embedding)-1]='PAD'\n",
    "dictionary['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "245215\n",
      "245214\n"
     ]
    }
   ],
   "source": [
    "print embedding[-1]\n",
    "print len(embedding)\n",
    "print dictionary['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rea',\n",
       " 're',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Processes a sentence to a fixed lenght of 38. This is the mean lenght of a sentence in my training data\n",
    "#Returns a padded sentence of the one we input\n",
    "def process_sentence(sentence,length=38):\n",
    "    length_sent=len(sentence)\n",
    "    if length_sent<length:\n",
    "        return_sent=[]\n",
    "        for i in range(length):\n",
    "            return_sent.append('PAD')\n",
    "        return_sent[:length_sent]=sentence\n",
    "    else:\n",
    "        return_sent=sentence[:length]\n",
    "    \n",
    "    \n",
    "    return return_sent\n",
    "\n",
    "\n",
    "    \n",
    "sent=['rea','re']\n",
    "process_sentence(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_indexes(padded_sent):\n",
    "    return_index=[]\n",
    "    for word in padded_sent:\n",
    "        if word in dictionary:\n",
    "            return_index.append(dictionary[word])\n",
    "        else:\n",
    "            return_index.append(dictionary['UNK'])\n",
    "    return return_index    \n",
    "\n",
    "# sent=['rea','re','coolio']\n",
    "# get_indexes(process_sentence(test_sentences[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "print len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# epoch/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "epoch=len(train_sentences)\n",
    "training_iters = epoch*20\n",
    "\n",
    "batch_size = 30\n",
    "display_step = epoch/batch_size\n",
    "# Network Parameters\n",
    "n_input = 128 #size of each word vector\n",
    "n_steps = 80 # timesteps in each sample. Average length of a word\n",
    "n_hidden = 200 # hidden layer num of features\n",
    "n_classes = 2 # total classes is 2 for positive or negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "#x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])   #Number of steps can be variable\n",
    "istate = tf.placeholder(\"float\", [None, 2*n_hidden]) #state & cell => 2x n_hidden\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    shape=_X.get_shape().as_list()  #Gets the shape of the tensor\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    \n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=0.9)\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, shape[1], _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, istate, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_next_batch(step):\n",
    "#     total_sent=len(train_sentences)\n",
    "#     sent=get_indexes(process_sentence(train_sentences[step%total_sent]))\n",
    "#     x_data=embedding[sent]\n",
    "#     y_data=train_labels[step%total_sent]\n",
    "#     return x_data,np.array(y_data)\n",
    "    \n",
    "def next_batch(batch_size,epoch,index_in_epoch,train_sentences,train_labels):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "#     if fake_data:\n",
    "#       fake_image = [1.0 for _ in xrange(784)]\n",
    "#       fake_label = 0\n",
    "#       return [fake_image for _ in xrange(batch_size)], [\n",
    "#           fake_label for _ in xrange(batch_size)]\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    if index_in_epoch > len(train_sentences):\n",
    "        # Finished epoch\n",
    "        epoch += 1\n",
    "        # Shuffle the data\n",
    "        perm = numpy.arange(len(train_sentences))\n",
    "        np.random.shuffle(perm)\n",
    "        train_sentences=train_sentences[perm]\n",
    "        train_labels=train_labels[perm]\n",
    "        # Start next epoch\n",
    "        start=0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= len(train_sentences)\n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "    end = index_in_epoch\n",
    "    sentences_batch=train_sentences[start:end]\n",
    "    sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in sentences_batch]\n",
    "    embed_sentence_batch=[embedding[sent] for sent in sentences_batch]\n",
    "    return embed_sentence_batch,train_labels[start:end]    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, Minibatch Loss= 10.419687, Training Accuracy= 0.43333\n",
      "epoch 1, Minibatch Loss= 0.638217, Training Accuracy= 0.60000\n",
      "epoch 2, Minibatch Loss= 0.635945, Training Accuracy= 0.60000\n",
      "epoch 3, Minibatch Loss= 0.371992, Training Accuracy= 0.86667\n",
      "epoch 4, Minibatch Loss= 0.133587, Training Accuracy= 0.96667\n",
      "epoch 5, Minibatch Loss= 0.007778, Training Accuracy= 1.00000\n",
      "epoch 6, Minibatch Loss= 0.000903, Training Accuracy= 1.00000\n",
      "epoch 7, Minibatch Loss= 0.000502, Training Accuracy= 1.00000\n",
      "epoch 8, Minibatch Loss= 0.000308, Training Accuracy= 1.00000\n",
      "epoch 9, Minibatch Loss= 0.000211, Training Accuracy= 1.00000\n",
      "epoch 10, Minibatch Loss= 0.000163, Training Accuracy= 1.00000\n",
      "epoch 11, Minibatch Loss= 0.000131, Training Accuracy= 1.00000\n",
      "epoch 12, Minibatch Loss= 0.000109, Training Accuracy= 1.00000\n",
      "epoch 13, Minibatch Loss= 0.000092, Training Accuracy= 1.00000\n",
      "epoch 14, Minibatch Loss= 0.000079, Training Accuracy= 1.00000\n",
      "epoch 15, Minibatch Loss= 0.000069, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.62\n",
      "Final Dev Accuracy 0.642023\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZKk8vl/wFk228MlE50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11785ebd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "def get_dev_accuracy():\n",
    "        \n",
    "        dev_len = len(dev_sentences)\n",
    "        dev_sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in dev_sentences]\n",
    "        dev_embed_sentence_batch=[embedding[sent] for sent in dev_sentences_batch]\n",
    "        dev_data = dev_embed_sentence_batch\n",
    "        dev_label = dev_labels\n",
    "        return sess.run(accuracy, feed_dict={x: dev_data, y: dev_label,\n",
    "                                                                 istate: np.zeros((dev_len, 2*n_hidden))})\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    epoch=0\n",
    "    index_in_epoch=0\n",
    "    epoch_count=0\n",
    "    # Keep training until reach max iterations\n",
    "    epoch_list=[]\n",
    "    dev_accuracy=[]\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = next_batch(batch_size,epoch,index_in_epoch,train_sentences,train_labels)\n",
    "#         print np.shape (batch_xs)\n",
    "#         break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        #batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))\n",
    "#         batch_ys=batch_ys.reshape((batch_size,n_classes))\n",
    "#         print np.shape(batch_xs)\n",
    "#         print np.shape(batch_ys)\n",
    "#         break\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                       istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                                istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                             istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            print \"epoch \" + str(epoch_count) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "            epoch_list.append(epoch_count)\n",
    "            dev_accuracy.append(get_dev_accuracy())\n",
    "            epoch_count+=1    \n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    test_len = len(test_sentences)\n",
    "    test_sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in test_sentences]\n",
    "    test_embed_sentence_batch=[embedding[sent] for sent in test_sentences_batch]\n",
    "    test_data = test_embed_sentence_batch\n",
    "    test_label = test_labels\n",
    "    print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                                             istate: np.zeros((test_len, 2*n_hidden))})\n",
    "    print \"Final Dev Accuracy\", get_dev_accuracy()\n",
    "    plt.plot(epoch_list,dev_accuracy,'ro')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy on Dev set')    \n",
    "    plt.savefig('dev_accuracy_'+str(n_steps)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Calculate accuracy for 256 mnist test images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a=tf.constant([[1,2,3],[3,4,5]])\n",
    "# a.get_shape().as_list()[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "a=np.ones(3)\n",
    "b=np.zeros(3)\n",
    "print np.vstack([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a3034ddda550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: reshape() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "a=[a,b]\n",
    "a=np.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x=np.array([10, 20, 38, 50, 70, 85, 100])\n",
    "# y=np.array([51.76, 55.0, 68, 63.8, 58.29,50.7,49.1])\n",
    "# #import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(x,y,'ro')\n",
    "\n",
    "# plt.savefig('plot.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dev_accuracy():\n",
    "        \n",
    "        dev_len = len(dev_sentences)\n",
    "        dev_sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in dev_sentences]\n",
    "        dev_embed_sentence_batch=[embedding[sent] for sent in dev_sentences_batch]\n",
    "        dev_data = dev_embed_sentence_batch\n",
    "        dev_label = dev_labels\n",
    "        return sess.run(accuracy, feed_dict={x: dev_data, y: dev_label,\n",
    "                                                                 istate: np.zeros((dev_len, 2*n_hidden))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_set=[10,20,38,50,65,80,100]\n",
    "dev_set_accuracy=[0,51.7,62.64,66.9,64.2,0,0]\n",
    "\n",
    "plt.plot(num_set,dev_set_accuracy,'ro')\n",
    "plt.xlabel('num_steps')\n",
    "plt.ylabel('Dev set classification accuracy')\n",
    "plt.savefig('classification_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
