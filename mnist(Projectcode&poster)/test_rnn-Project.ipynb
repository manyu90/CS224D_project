{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.models.rnn import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding=np.loadtxt('../../Project_cs224D/w2v_data1Bmedline/embedding_matrix')\n",
    "with open('../../Project_cs224D/w2v_data1Bmedline/dictionary.pickle','rb') as handle:\n",
    "    dictionary=pickle.load(handle)\n",
    "with open('../../Project_cs224D/w2v_data1Bmedline/reverse_dictionary.pickle','rb') as handle:\n",
    "    reverse_dictionary=pickle.load(handle)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245214\n"
     ]
    }
   ],
   "source": [
    "print len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Relations/relations_label_dict.pickle','rb') as handle:\n",
    "    relations=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences, labels = zip(*[(key, value) for (key, value) in relations.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping={-1:(0,1),1:(1,0)}\n",
    "labels=[mapping[label] for label in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DEFINING THE TRAINING AND TESTING DATA HERE\n",
    "\n",
    "\n",
    "train_sentences=sentences[:900]\n",
    "test_sentences=sentences[900:]\n",
    "train_labels=labels[:900]\n",
    "test_labels=labels[900:]\n",
    "#print len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths_sents=[len(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###ADDED THE PAD symbol to the embedding at the end. IT is all zeros\n",
    "###The dictionary is updated as well\n",
    "\n",
    "embedding=np.vstack([embedding,np.zeros(128)])\n",
    "dictionary['PAD']=len(embedding)-1\n",
    "reverse_dictionary[len(embedding)-1]='PAD'\n",
    "dictionary['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "245215\n",
      "245214\n"
     ]
    }
   ],
   "source": [
    "print embedding[-1]\n",
    "print len(embedding)\n",
    "print dictionary['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rea',\n",
       " 're',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Processes a sentence to a fixed lenght of 38. This is the mean lenght of a sentence in my training data\n",
    "#Returns a padded sentence of the one we input\n",
    "def process_sentence(sentence,length=38):\n",
    "    length_sent=len(sentence)\n",
    "    if length_sent<length:\n",
    "        return_sent=[]\n",
    "        for i in range(length):\n",
    "            return_sent.append('PAD')\n",
    "        return_sent[:length_sent]=sentence\n",
    "    else:\n",
    "        return_sent=sentence[:length]\n",
    "    \n",
    "    \n",
    "    return return_sent\n",
    "\n",
    "\n",
    "    \n",
    "sent=['rea','re']\n",
    "process_sentence(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_indexes(padded_sent):\n",
    "    return_index=[]\n",
    "    for word in padded_sent:\n",
    "        if word in dictionary:\n",
    "            return_index.append(dictionary[word])\n",
    "        else:\n",
    "            return_index.append(dictionary['UNK'])\n",
    "    return return_index    \n",
    "\n",
    "# sent=['rea','re','coolio']\n",
    "# get_indexes(process_sentence(test_sentences[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "print len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 20000\n",
    "display_step = 100\n",
    "batch_size = 30\n",
    "# Network Parameters\n",
    "n_input = 128 #size of each word vector\n",
    "n_steps = 38 # timesteps in each sample. Average length of a word\n",
    "n_hidden = 200 # hidden layer num of features\n",
    "n_classes = 2 # total classes is 2 for positive or negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "#x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])   #Number of steps can be variable\n",
    "istate = tf.placeholder(\"float\", [None, 2*n_hidden]) #state & cell => 2x n_hidden\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    shape=_X.get_shape().as_list()  #Gets the shape of the tensor\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    \n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=0.9)\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, shape[1], _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, istate, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_next_batch(step):\n",
    "#     total_sent=len(train_sentences)\n",
    "#     sent=get_indexes(process_sentence(train_sentences[step%total_sent]))\n",
    "#     x_data=embedding[sent]\n",
    "#     y_data=train_labels[step%total_sent]\n",
    "#     return x_data,np.array(y_data)\n",
    "    \n",
    "def next_batch(batch_size,epoch,index_in_epoch,train_sentences,train_labels):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "#     if fake_data:\n",
    "#       fake_image = [1.0 for _ in xrange(784)]\n",
    "#       fake_label = 0\n",
    "#       return [fake_image for _ in xrange(batch_size)], [\n",
    "#           fake_label for _ in xrange(batch_size)]\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    if index_in_epoch > len(train_sentences):\n",
    "        # Finished epoch\n",
    "        epoch += 1\n",
    "        # Shuffle the data\n",
    "        perm = numpy.arange(len(train_sentences))\n",
    "        np.random.shuffle(perm)\n",
    "        train_sentences=train_sentences[perm]\n",
    "        train_labels=train_labels[perm]\n",
    "        # Start next epoch\n",
    "        start=0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= len(train_sentences)\n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "    end = index_in_epoch\n",
    "    sentences_batch=train_sentences[start:end]\n",
    "    sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in sentences_batch]\n",
    "    embed_sentence_batch=[embedding[sent] for sent in sentences_batch]\n",
    "    return embed_sentence_batch,train_labels[start:end]    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 14.615818, Training Accuracy= 0.46667\n",
      "Iter 3000, Minibatch Loss= 0.097482, Training Accuracy= 1.00000\n",
      "Iter 6000, Minibatch Loss= 0.001437, Training Accuracy= 1.00000\n",
      "Iter 9000, Minibatch Loss= 0.000338, Training Accuracy= 1.00000\n",
      "Iter 12000, Minibatch Loss= 0.000155, Training Accuracy= 1.00000\n",
      "Iter 15000, Minibatch Loss= 0.000096, Training Accuracy= 1.00000\n",
      "Iter 18000, Minibatch Loss= 0.000067, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.628141\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    epoch=0\n",
    "    index_in_epoch=0\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = next_batch(batch_size,epoch,index_in_epoch,train_sentences,train_labels)\n",
    "#         print np.shape (batch_xs)\n",
    "#         break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        #batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))\n",
    "#         batch_ys=batch_ys.reshape((batch_size,n_classes))\n",
    "#         print np.shape(batch_xs)\n",
    "#         print np.shape(batch_ys)\n",
    "#         break\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                       istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                                istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                             istate: np.zeros((batch_size, 2*n_hidden))})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    test_len = len(test_sentences)\n",
    "    test_sentences_batch=[get_indexes(process_sentence(sent,n_steps)) for sent in test_sentences]\n",
    "    test_embed_sentence_batch=[embedding[sent] for sent in test_sentences_batch]\n",
    "    test_data = test_embed_sentence_batch\n",
    "    test_label = test_labels\n",
    "    print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                                             istate: np.zeros((test_len, 2*n_hidden))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Calculate accuracy for 256 mnist test images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6f248894d352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "a=tf.constant([[1,2,3],[3,4,5]])\n",
    "a.get_shape().as_list()[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.ones(3)\n",
    "b=np.zeros(3)\n",
    "print np.vstack([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[a,b]\n",
    "a=np.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([10, 20, 38, 50, 70, 85, 100])\n",
    "y=np.array([51.76, 55.0, 68, 63.8, 58.29,50.7,49.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
